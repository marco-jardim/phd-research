{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Estrat√©gia de M√°xima PRECIS√ÉO para Data Linkage\n",
    "## Objetivo: Minimizar Falsos Positivos - Pares de Alta Confian√ßa\n",
    "\n",
    "Este notebook implementa uma estrat√©gia conservadora para **maximizar a precis√£o** do linkage, priorizando a identifica√ß√£o de pares com alta confian√ßa e minimizando a necessidade de revis√£o manual.\n",
    "\n",
    "### T√©cnicas Implementadas:\n",
    "1. **Stacking com Meta-Learner Conservador** - Combina modelos com regra final rigorosa\n",
    "2. **Threshold Otimizado para Precis√£o** - Ponto de corte alto\n",
    "3. **Regras de Neg√≥cio** - Filtros adicionais baseados em conhecimento do dom√≠nio\n",
    "4. **Isolation Forest** - Detec√ß√£o de anomalias para filtrar outliers\n",
    "5. **Calibra√ß√£o de Probabilidades** - Probabilidades mais confi√°veis\n",
    "6. **Consensus Voting** - Apenas classifica como par se m√∫ltiplos modelos concordam\n",
    "7. **Feature Selection Rigorosa** - Apenas features mais discriminativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala√ß√£o de depend√™ncias\n",
    "!pip install -q pandas numpy scikit-learn xgboost lightgbm imbalanced-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier,\n",
    "    StackingClassifier, IsolationForest, ExtraTreesClassifier\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.feature_selection import SelectFromModel, RFE\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    precision_recall_curve, f1_score, precision_score, recall_score,\n",
    "    average_precision_score\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√µes\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Bibliotecas carregadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregamento e Prepara√ß√£o dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados\n",
    "from pathlib import Path\n",
    "\n",
    "def find_data_path(filename: str = 'COMPARADORSEMIDENT.csv') -> Path:\n",
    "    for base in (Path.cwd(), *Path.cwd().parents):\n",
    "        candidate = base / 'data' / filename\n",
    "        if candidate.exists():\n",
    "            return candidate\n",
    "    raise FileNotFoundError(\n",
    "        f\"Nao foi possivel localizar data/{filename}. CWD={Path.cwd()}\"\n",
    "    )\n",
    "\n",
    "DATA_PATH = find_data_path()\n",
    "df = pd.read_csv(DATA_PATH, sep=';', low_memory=False)\n",
    "print(f\"Lendo arquivo: {DATA_PATH.resolve()}\")\n",
    "\n",
    "# Limpar nomes das colunas\n",
    "def clean_col(col):\n",
    "    return col.split(',')[0] if ',' in col else col\n",
    "df.columns = [clean_col(c) for c in df.columns]\n",
    "\n",
    "# Converter colunas num√©ricas\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == object:\n",
    "        try:\n",
    "            df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', '.'), errors='coerce')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# Target\n",
    "df['TARGET'] = (df['PAR'].isin([1, 2])).astype(int)\n",
    "\n",
    "print(f\"Dataset: {df.shape[0]:,} registros\")\n",
    "print(f\"Pares verdadeiros: {df['TARGET'].sum()} ({df['TARGET'].mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering focado em PRECIS√ÉO\n",
    "# Usar apenas features mais discriminativas e criar combina√ß√µes de alta confian√ßa\n",
    "\n",
    "SCORE_COLS = [\n",
    "    'NOME prim frag igual', 'NOME ult frag igual', 'NOME qtd frag iguais',\n",
    "    'NOME qtd frag raros', 'NOME qtd frag comuns', 'NOME qtd frag muito parec', 'NOME qtd frag abrev',\n",
    "    'NOMEMAE prim frag igual', 'NOMEMAE ult frag igual', 'NOMEMAE qtd frag iguais',\n",
    "    'NOMEMAE qtd frag raros', 'NOMEMAE qtd frag comuns', 'NOMEMAE qtd frag muito parec',\n",
    "    'DTNASC dt iguais', 'DTNASC dt ap 1digi', 'DTNASC dt inv dia', 'DTNASC dt inv mes', 'DTNASC dt inv ano',\n",
    "    'CODMUNRES uf igual', 'CODMUNRES local igual', 'CODMUNRES local prox',\n",
    "    'ENDERECO via igual', 'ENDERECO via prox', 'ENDERECO numero igual',\n",
    "    'ENDERECO compl prox', 'ENDERECO texto prox', 'ENDERECO tokens jacc',\n",
    "    'nota final'\n",
    "]\n",
    "\n",
    "available_cols = [c for c in SCORE_COLS if c in df.columns]\n",
    "X = df[available_cols].fillna(0).copy()\n",
    "\n",
    "print(f\"Features base: {len(available_cols)}\")\n",
    "\n",
    "# ============================================\n",
    "# FEATURE ENGINEERING PARA PRECIS√ÉO\n",
    "# ============================================\n",
    "\n",
    "# 1. Scores agregados com pesos conservadores\n",
    "X['nome_total'] = (X['NOME prim frag igual'] * 0.3 + \n",
    "                   X['NOME ult frag igual'] * 0.3 + \n",
    "                   X['NOME qtd frag iguais'] * 0.4)\n",
    "\n",
    "X['mae_total'] = (X['NOMEMAE prim frag igual'] * 0.25 + \n",
    "                  X['NOMEMAE ult frag igual'] * 0.25 + \n",
    "                  X['NOMEMAE qtd frag iguais'] * 0.5)\n",
    "\n",
    "# 2. Flags de alta confian√ßa (crit√©rios rigorosos)\n",
    "X['nome_perfeito'] = (X['NOME qtd frag iguais'] >= 0.95).astype(int)\n",
    "X['nome_excelente'] = (X['NOME qtd frag iguais'] >= 0.85).astype(int)\n",
    "X['dtnasc_exato'] = (X['DTNASC dt iguais'] == 1).astype(int)\n",
    "X['dtnasc_quase'] = ((X['DTNASC dt iguais'] == 1) | (X['DTNASC dt ap 1digi'] == 1)).astype(int)\n",
    "X['mae_forte'] = (X['NOMEMAE qtd frag iguais'] >= 0.6).astype(int)\n",
    "X['local_exato'] = (X['CODMUNRES local igual'] == 1).astype(int)\n",
    "X['endereco_match'] = (X['ENDERECO via igual'] == 1).astype(int)\n",
    "\n",
    "# 3. Score de precis√£o (combina√ß√£o de evid√™ncias fortes)\n",
    "X['score_precisao'] = (\n",
    "    X['nome_perfeito'] * 3.0 +\n",
    "    X['dtnasc_exato'] * 3.0 +\n",
    "    X['mae_forte'] * 2.0 +\n",
    "    X['local_exato'] * 1.5 +\n",
    "    X['endereco_match'] * 1.0\n",
    ")\n",
    "\n",
    "# 4. Contagem de crit√©rios de alta confian√ßa atendidos\n",
    "X['criterios_fortes'] = (\n",
    "    X['nome_perfeito'] + X['dtnasc_exato'] + X['mae_forte'] + \n",
    "    X['local_exato'] + X['endereco_match']\n",
    ")\n",
    "\n",
    "# 5. M√≠nimos (para garantir consist√™ncia)\n",
    "X['min_nome_mae'] = X[['nome_total', 'mae_total']].min(axis=1)\n",
    "X['min_nome_dtnasc'] = X[['NOME qtd frag iguais', 'DTNASC dt iguais']].min(axis=1)\n",
    "\n",
    "# 6. Intera√ß√µes de alta confian√ßa\n",
    "X['nome_e_dtnasc'] = X['nome_perfeito'] * X['dtnasc_exato']\n",
    "X['nome_e_mae'] = X['nome_perfeito'] * X['mae_forte']\n",
    "X['dtnasc_e_local'] = X['dtnasc_exato'] * X['local_exato']\n",
    "X['trifecta'] = X['nome_perfeito'] * X['dtnasc_exato'] * X['mae_forte']  # Tripla confirma√ß√£o\n",
    "\n",
    "# 7. Vari√°veis do contexto\n",
    "X['obito_sinan'] = df['C_SITUENCE'].isin([3, 4]).astype(int)\n",
    "\n",
    "# 8. Diferen√ßa de datas\n",
    "df['R_DT_ANO'] = df['R_DTNASC'].astype(str).str[:4].astype(float)\n",
    "df['C_DT_ANO'] = df['C_DTNASC'].astype(str).str[:4].astype(float)\n",
    "X['diff_ano'] = np.abs(df['R_DT_ANO'] - df['C_DT_ANO']).fillna(99)\n",
    "X['ano_consistente'] = (X['diff_ano'] <= 2).astype(int)  # Crit√©rio rigoroso: m√°x 2 anos\n",
    "\n",
    "# 9. Nota final ao quadrado (amplifica diferen√ßas)\n",
    "X['nota_squared'] = X['nota final'] ** 2\n",
    "X['nota_cubed'] = X['nota final'] ** 3\n",
    "\n",
    "print(f\"\\nTotal de features ap√≥s engineering: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dados\n",
    "y = df['TARGET'].copy()\n",
    "\n",
    "# Divis√£o estratificada\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Guardar √≠ndices\n",
    "train_idx = X_train.index\n",
    "test_idx = X_test.index\n",
    "\n",
    "print(f\"Treino: {len(X_train):,} ({y_train.sum()} pares)\")\n",
    "print(f\"Teste: {len(X_test):,} ({y_test.sum()} pares)\")\n",
    "\n",
    "# Normaliza√ß√£o\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sele√ß√£o de Features Rigorosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar apenas as features mais importantes\n",
    "print(\"Selecionando features mais discriminativas...\\n\")\n",
    "\n",
    "# Usar Random Forest para feature importance\n",
    "rf_selector = RandomForestClassifier(\n",
    "    n_estimators=200, max_depth=10, \n",
    "    class_weight='balanced', random_state=42, n_jobs=-1\n",
    ")\n",
    "rf_selector.fit(X_train, y_train)\n",
    "\n",
    "# Import√¢ncia das features\n",
    "feature_imp = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf_selector.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 15 Features mais importantes:\")\n",
    "print(feature_imp.head(15).to_string(index=False))\n",
    "\n",
    "# Selecionar top features\n",
    "TOP_N_FEATURES = 25\n",
    "selected_features = feature_imp.head(TOP_N_FEATURES)['feature'].tolist()\n",
    "\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "print(f\"\\nFeatures selecionadas: {len(selected_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelos Otimizados para Precis√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o de avalia√ß√£o\n",
    "def evaluate_precision_model(model, X_tr, y_tr, X_te, y_te, model_name, threshold=0.5):\n",
    "    model.fit(X_tr, y_tr)\n",
    "    \n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_proba = model.predict_proba(X_te)[:, 1]\n",
    "    else:\n",
    "        y_proba = model.decision_function(X_te)\n",
    "        y_proba = (y_proba - y_proba.min()) / (y_proba.max() - y_proba.min())\n",
    "    \n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    \n",
    "    return {\n",
    "        'name': model_name,\n",
    "        'threshold': threshold,\n",
    "        'precision': precision_score(y_te, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_te, y_pred),\n",
    "        'f1': f1_score(y_te, y_pred),\n",
    "        'auc_roc': roc_auc_score(y_te, y_proba),\n",
    "        'auc_pr': average_precision_score(y_te, y_proba),\n",
    "        'n_positivos': y_pred.sum(),\n",
    "        'y_proba': y_proba,\n",
    "        'model': model\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar SMOTE moderado (n√£o extremo, para manter qualidade)\n",
    "smote = SMOTE(sampling_strategy=0.3, random_state=42, k_neighbors=5)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_selected, y_train)\n",
    "\n",
    "print(f\"Ap√≥s SMOTE: {len(y_train_smote):,} amostras ({y_train_smote.sum():,} pares)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar modelos com diferentes thresholds altos\n",
    "results = []\n",
    "\n",
    "print(\"Treinando modelos otimizados para precis√£o...\\n\")\n",
    "\n",
    "# 1. XGBoost com regulariza√ß√£o forte\n",
    "xgb_precision = xgb.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=4,  # Raso para evitar overfitting\n",
    "    learning_rate=0.05,\n",
    "    reg_alpha=1.0,  # L1 regularization\n",
    "    reg_lambda=2.0,  # L2 regularization\n",
    "    scale_pos_weight=10,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "for th in [0.6, 0.7, 0.8, 0.9]:\n",
    "    res = evaluate_precision_model(\n",
    "        xgb_precision, X_train_smote.values, y_train_smote, \n",
    "        X_test_selected.values, y_test, f'XGBoost (th={th})', threshold=th\n",
    "    )\n",
    "    results.append(res)\n",
    "    print(f\"{res['name']}: Precision={res['precision']:.4f}, Recall={res['recall']:.4f}, N={res['n_positivos']}\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. LightGBM com configura√ß√£o conservadora\n",
    "lgb_precision = lgb.LGBMClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=15,  # Conservador\n",
    "    min_child_samples=50,  # Evita overfitting\n",
    "    reg_alpha=0.5,\n",
    "    reg_lambda=1.0,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "for th in [0.6, 0.7, 0.8, 0.9]:\n",
    "    res = evaluate_precision_model(\n",
    "        lgb_precision, X_train_smote.values, y_train_smote,\n",
    "        X_test_selected.values, y_test, f'LightGBM (th={th})', threshold=th\n",
    "    )\n",
    "    results.append(res)\n",
    "    print(f\"{res['name']}: Precision={res['precision']:.4f}, Recall={res['recall']:.4f}, N={res['n_positivos']}\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Random Forest com calibra√ß√£o de probabilidades\n",
    "print(\"Treinando Random Forest com calibra√ß√£o...\")\n",
    "\n",
    "rf_base = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=10,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_calibrated = CalibratedClassifierCV(rf_base, method='isotonic', cv=5)\n",
    "\n",
    "for th in [0.7, 0.8, 0.9]:\n",
    "    res = evaluate_precision_model(\n",
    "        rf_calibrated, X_train_smote.values, y_train_smote,\n",
    "        X_test_selected.values, y_test, f'RF Calibrado (th={th})', threshold=th\n",
    "    )\n",
    "    results.append(res)\n",
    "    print(f\"{res['name']}: Precision={res['precision']:.4f}, Recall={res['recall']:.4f}, N={res['n_positivos']}\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stacking com Meta-Learner Conservador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking: combina modelos com meta-learner que prioriza precis√£o\n",
    "print(\"Construindo Stacking Classifier...\\n\")\n",
    "\n",
    "base_estimators = [\n",
    "    ('xgb', xgb.XGBClassifier(\n",
    "        n_estimators=150, max_depth=4, learning_rate=0.05,\n",
    "        random_state=42, use_label_encoder=False, eval_metric='logloss'\n",
    "    )),\n",
    "    ('lgb', lgb.LGBMClassifier(\n",
    "        n_estimators=150, max_depth=4, learning_rate=0.05,\n",
    "        random_state=42, verbose=-1\n",
    "    )),\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=150, max_depth=6, class_weight='balanced',\n",
    "        random_state=42, n_jobs=-1\n",
    "    )),\n",
    "    ('gb', GradientBoostingClassifier(\n",
    "        n_estimators=100, max_depth=4, learning_rate=0.05,\n",
    "        random_state=42\n",
    "    ))\n",
    "]\n",
    "\n",
    "# Meta-learner: Logistic Regression com regulariza√ß√£o forte\n",
    "meta_learner = LogisticRegression(\n",
    "    C=0.1,  # Regulariza√ß√£o forte\n",
    "    class_weight='balanced',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "stacking_precision = StackingClassifier(\n",
    "    estimators=base_estimators,\n",
    "    final_estimator=meta_learner,\n",
    "    cv=5,\n",
    "    passthrough=True,  # Inclui features originais\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "stacking_precision.fit(X_train_smote.values, y_train_smote)\n",
    "y_proba_stack = stacking_precision.predict_proba(X_test_selected.values)[:, 1]\n",
    "\n",
    "print(\"Performance do Stacking com diferentes thresholds:\")\n",
    "for th in [0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "    y_pred_stack = (y_proba_stack >= th).astype(int)\n",
    "    prec = precision_score(y_test, y_pred_stack, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred_stack)\n",
    "    n_pos = y_pred_stack.sum()\n",
    "    print(f\"  Threshold {th}: Precision={prec:.4f}, Recall={rec:.4f}, N={n_pos}\")\n",
    "    \n",
    "    if th == 0.8:  # Guardar resultado com threshold alto\n",
    "        results.append({\n",
    "            'name': f'Stacking (th={th})',\n",
    "            'threshold': th,\n",
    "            'precision': prec,\n",
    "            'recall': rec,\n",
    "            'f1': f1_score(y_test, y_pred_stack),\n",
    "            'auc_roc': roc_auc_score(y_test, y_proba_stack),\n",
    "            'auc_pr': average_precision_score(y_test, y_proba_stack),\n",
    "            'n_positivos': n_pos,\n",
    "            'y_proba': y_proba_stack,\n",
    "            'model': stacking_precision\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Consensus Voting (Unanimidade entre Modelos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consensus: S√≥ classifica como par se TODOS os modelos concordam\n",
    "print(\"\\nImplementando Consensus Voting...\\n\")\n",
    "\n",
    "# Treinar modelos individuais\n",
    "models_consensus = {\n",
    "    'XGBoost': xgb.XGBClassifier(\n",
    "        n_estimators=200, max_depth=5, random_state=42,\n",
    "        use_label_encoder=False, eval_metric='logloss'\n",
    "    ),\n",
    "    'LightGBM': lgb.LGBMClassifier(\n",
    "        n_estimators=200, max_depth=5, random_state=42, verbose=-1\n",
    "    ),\n",
    "    'RandomForest': RandomForestClassifier(\n",
    "        n_estimators=200, max_depth=8, class_weight='balanced',\n",
    "        random_state=42, n_jobs=-1\n",
    "    ),\n",
    "    'GradientBoosting': GradientBoostingClassifier(\n",
    "        n_estimators=150, max_depth=4, random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "predictions = {}\n",
    "probas = {}\n",
    "\n",
    "for name, model in models_consensus.items():\n",
    "    model.fit(X_train_smote.values, y_train_smote)\n",
    "    probas[name] = model.predict_proba(X_test_selected.values)[:, 1]\n",
    "    predictions[name] = (probas[name] >= 0.7).astype(int)  # Threshold individual alto\n",
    "    \n",
    "    prec = precision_score(y_test, predictions[name], zero_division=0)\n",
    "    rec = recall_score(y_test, predictions[name])\n",
    "    print(f\"{name}: Precision={prec:.4f}, Recall={rec:.4f}\")\n",
    "\n",
    "# Consensus: apenas se todos concordam\n",
    "consensus_pred = np.ones(len(y_test))\n",
    "for pred in predictions.values():\n",
    "    consensus_pred = consensus_pred * pred\n",
    "\n",
    "consensus_proba = np.mean([p for p in probas.values()], axis=0)\n",
    "\n",
    "print(f\"\\n>>> CONSENSUS (todos concordam):\")\n",
    "print(f\"    Precision: {precision_score(y_test, consensus_pred, zero_division=0):.4f}\")\n",
    "print(f\"    Recall: {recall_score(y_test, consensus_pred):.4f}\")\n",
    "print(f\"    N positivos: {int(consensus_pred.sum())}\")\n",
    "\n",
    "results.append({\n",
    "    'name': 'Consensus (unanimidade)',\n",
    "    'threshold': 0.7,\n",
    "    'precision': precision_score(y_test, consensus_pred, zero_division=0),\n",
    "    'recall': recall_score(y_test, consensus_pred),\n",
    "    'f1': f1_score(y_test, consensus_pred),\n",
    "    'auc_roc': roc_auc_score(y_test, consensus_proba),\n",
    "    'auc_pr': average_precision_score(y_test, consensus_proba),\n",
    "    'n_positivos': int(consensus_pred.sum()),\n",
    "    'y_proba': consensus_proba,\n",
    "    'model': models_consensus\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Regras de Neg√≥cio para Alta Confian√ßa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementar regras baseadas em conhecimento do dom√≠nio\n",
    "print(\"Aplicando regras de neg√≥cio para alta confian√ßa...\\n\")\n",
    "\n",
    "def regras_alta_confianca(row):\n",
    "    \"\"\"\n",
    "    Retorna 1 se o registro atende crit√©rios de alta confian√ßa.\n",
    "    M√∫ltiplas evid√™ncias fortes devem estar presentes.\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    \n",
    "    # Regra 1: Nome quase perfeito\n",
    "    if row['NOME qtd frag iguais'] >= 0.95:\n",
    "        score += 3\n",
    "    elif row['NOME qtd frag iguais'] >= 0.85:\n",
    "        score += 2\n",
    "    \n",
    "    # Regra 2: Data de nascimento exata ou muito pr√≥xima\n",
    "    if row['DTNASC dt iguais'] == 1:\n",
    "        score += 3\n",
    "    elif row['DTNASC dt ap 1digi'] == 1:\n",
    "        score += 1.5\n",
    "    \n",
    "    # Regra 3: Nome da m√£e presente e similar\n",
    "    if row['NOMEMAE qtd frag iguais'] >= 0.7:\n",
    "        score += 2\n",
    "    elif row['NOMEMAE qtd frag iguais'] >= 0.5:\n",
    "        score += 1\n",
    "    \n",
    "    # Regra 4: Munic√≠pio igual\n",
    "    if row['CODMUNRES local igual'] == 1:\n",
    "        score += 1.5\n",
    "    \n",
    "    # Regra 5: Endere√ßo matching\n",
    "    if row['ENDERECO via igual'] == 1:\n",
    "        score += 1\n",
    "    \n",
    "    # Regra 6: Nota final alta do OpenRecLink\n",
    "    if row['nota final'] >= 9:\n",
    "        score += 2\n",
    "    elif row['nota final'] >= 8:\n",
    "        score += 1\n",
    "    \n",
    "    return score\n",
    "\n",
    "# Aplicar regras\n",
    "X_test_full = df.loc[test_idx].copy()\n",
    "X_test_full['score_regras'] = X_test_full.apply(regras_alta_confianca, axis=1)\n",
    "\n",
    "# Testar diferentes limiares\n",
    "print(\"Performance das regras de neg√≥cio:\")\n",
    "for limiar in [6, 7, 8, 9, 10]:\n",
    "    pred_regras = (X_test_full['score_regras'] >= limiar).astype(int)\n",
    "    prec = precision_score(y_test, pred_regras, zero_division=0)\n",
    "    rec = recall_score(y_test, pred_regras)\n",
    "    n_pos = pred_regras.sum()\n",
    "    print(f\"  Limiar {limiar}: Precision={prec:.4f}, Recall={rec:.4f}, N={n_pos}\")\n",
    "\n",
    "# Guardar melhor resultado de regras\n",
    "best_limiar = 8\n",
    "pred_regras_final = (X_test_full['score_regras'] >= best_limiar).astype(int)\n",
    "proba_regras = X_test_full['score_regras'] / X_test_full['score_regras'].max()\n",
    "\n",
    "results.append({\n",
    "    'name': f'Regras de Neg√≥cio (limiar={best_limiar})',\n",
    "    'threshold': best_limiar,\n",
    "    'precision': precision_score(y_test, pred_regras_final, zero_division=0),\n",
    "    'recall': recall_score(y_test, pred_regras_final),\n",
    "    'f1': f1_score(y_test, pred_regras_final),\n",
    "    'auc_roc': roc_auc_score(y_test, proba_regras),\n",
    "    'auc_pr': average_precision_score(y_test, proba_regras),\n",
    "    'n_positivos': int(pred_regras_final.sum()),\n",
    "    'y_proba': proba_regras.values,\n",
    "    'model': 'rules'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. H√≠brido: ML + Regras de Neg√≥cio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar ML com regras de neg√≥cio para m√°xima precis√£o\n",
    "print(\"Combinando ML + Regras de Neg√≥cio...\\n\")\n",
    "\n",
    "# S√≥ classifica como par se:\n",
    "# 1. ML diz que √© par (proba >= threshold)\n",
    "# 2. E atende regras de neg√≥cio (score >= limiar)\n",
    "\n",
    "ml_proba = y_proba_stack  # Usar stacking\n",
    "regras_score = X_test_full['score_regras'].values\n",
    "\n",
    "print(\"Performance do modelo h√≠brido (ML + Regras):\")\n",
    "for ml_th in [0.5, 0.6, 0.7]:\n",
    "    for regra_th in [5, 6, 7]:\n",
    "        pred_hibrido = ((ml_proba >= ml_th) & (regras_score >= regra_th)).astype(int)\n",
    "        prec = precision_score(y_test, pred_hibrido, zero_division=0)\n",
    "        rec = recall_score(y_test, pred_hibrido)\n",
    "        n_pos = pred_hibrido.sum()\n",
    "        if prec > 0.5 and n_pos > 0:  # S√≥ mostrar se tem boa precis√£o\n",
    "            print(f\"  ML>={ml_th} & Regras>={regra_th}: Precision={prec:.4f}, Recall={rec:.4f}, N={n_pos}\")\n",
    "\n",
    "# Melhor combina√ß√£o\n",
    "best_ml_th = 0.6\n",
    "best_regra_th = 6\n",
    "pred_hibrido_final = ((ml_proba >= best_ml_th) & (regras_score >= best_regra_th)).astype(int)\n",
    "proba_hibrido = (ml_proba + regras_score/10) / 2  # M√©dia ponderada\n",
    "\n",
    "results.append({\n",
    "    'name': f'H√≠brido ML+Regras',\n",
    "    'threshold': f'ML‚â•{best_ml_th}, Regras‚â•{best_regra_th}',\n",
    "    'precision': precision_score(y_test, pred_hibrido_final, zero_division=0),\n",
    "    'recall': recall_score(y_test, pred_hibrido_final),\n",
    "    'f1': f1_score(y_test, pred_hibrido_final),\n",
    "    'auc_roc': roc_auc_score(y_test, proba_hibrido),\n",
    "    'auc_pr': average_precision_score(y_test, proba_hibrido),\n",
    "    'n_positivos': int(pred_hibrido_final.sum()),\n",
    "    'y_proba': proba_hibrido,\n",
    "    'model': 'hybrid'\n",
    "})\n",
    "\n",
    "print(f\"\\n>>> H√≠brido final: Precision={results[-1]['precision']:.4f}, Recall={results[-1]['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compara√ß√£o e Sele√ß√£o do Melhor Modelo para Precis√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar DataFrame de resultados\n",
    "df_results = pd.DataFrame([{\n",
    "    'Modelo': r['name'],\n",
    "    'Precision': r['precision'],\n",
    "    'Recall': r['recall'],\n",
    "    'F1': r['f1'],\n",
    "    'AUC-PR': r['auc_pr'],\n",
    "    'N_Positivos': r['n_positivos']\n",
    "} for r in results])\n",
    "\n",
    "# Filtrar apenas modelos com recall > 0 e precision razo√°vel\n",
    "df_results = df_results[df_results['Recall'] > 0]\n",
    "df_results = df_results.sort_values('Precision', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"RANKING DE MODELOS POR PRECIS√ÉO\")\n",
    "print(\"=\"*100)\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "# Identificar melhor modelo (precision > 50% com recall razo√°vel)\n",
    "df_good = df_results[(df_results['Precision'] >= 0.5) & (df_results['Recall'] >= 0.2)]\n",
    "if len(df_good) > 0:\n",
    "    best_model_name = df_good.iloc[0]['Modelo']\n",
    "else:\n",
    "    best_model_name = df_results.iloc[0]['Modelo']\n",
    "\n",
    "best_result = [r for r in results if r['name'] == best_model_name][0]\n",
    "\n",
    "print(f\"\\nüèÜ MELHOR MODELO PARA PRECIS√ÉO: {best_model_name}\")\n",
    "print(f\"   Precision: {best_result['precision']:.4f}\")\n",
    "print(f\"   Recall: {best_result['recall']:.4f}\")\n",
    "print(f\"   Candidatos identificados: {best_result['n_positivos']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√£o\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Precision vs Recall\n",
    "ax1 = axes[0]\n",
    "colors = plt.cm.RdYlGn(df_results['Precision'].values)\n",
    "scatter = ax1.scatter(df_results['Recall'], df_results['Precision'], \n",
    "                      c=df_results['Precision'], cmap='RdYlGn', \n",
    "                      s=200, edgecolors='black', linewidth=1)\n",
    "\n",
    "# Adicionar labels\n",
    "for idx, row in df_results.iterrows():\n",
    "    if row['Precision'] > 0.3:  # S√≥ labels para modelos relevantes\n",
    "        ax1.annotate(row['Modelo'][:15], \n",
    "                     (row['Recall'], row['Precision']),\n",
    "                     fontsize=8, ha='center', va='bottom')\n",
    "\n",
    "ax1.axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='Precision 50%')\n",
    "ax1.set_xlabel('Recall', fontsize=12)\n",
    "ax1.set_ylabel('Precision', fontsize=12)\n",
    "ax1.set_title('Trade-off Precision vs Recall (Estrat√©gia de Precis√£o)', fontsize=14)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter, ax=ax1, label='Precision')\n",
    "\n",
    "# Plot 2: Top modelos por Precision\n",
    "ax2 = axes[1]\n",
    "top_models = df_results.head(10)\n",
    "colors = plt.cm.Greens(np.linspace(0.3, 0.9, len(top_models)))\n",
    "bars = ax2.barh(range(len(top_models)), top_models['Precision'], color=colors, edgecolor='black')\n",
    "ax2.set_yticks(range(len(top_models)))\n",
    "ax2.set_yticklabels([m[:25] for m in top_models['Modelo']])\n",
    "ax2.set_xlabel('Precision', fontsize=12)\n",
    "ax2.set_title('Top 10 Modelos por Precis√£o', fontsize=14)\n",
    "ax2.axvline(x=0.5, color='red', linestyle='--', label='Meta 50%')\n",
    "ax2.legend()\n",
    "\n",
    "for bar, val, n in zip(bars, top_models['Precision'], top_models['N_Positivos']):\n",
    "    ax2.text(val + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "             f'{val:.2f} (N={int(n)})', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('precision_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Aplica√ß√£o aos Dados Completos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar modelo final em todos os dados\n",
    "print(\"Aplicando modelo de alta precis√£o a todos os dados...\\n\")\n",
    "\n",
    "# Retreinar com todos os dados\n",
    "X_all_selected = X[selected_features]\n",
    "smote_final = SMOTE(sampling_strategy=0.3, random_state=42)\n",
    "X_all_smote, y_all_smote = smote_final.fit_resample(X_all_selected, y)\n",
    "\n",
    "# Treinar stacking final\n",
    "stacking_precision.fit(X_all_smote.values, y_all_smote)\n",
    "y_proba_all = stacking_precision.predict_proba(X_all_selected.values)[:, 1]\n",
    "\n",
    "# Calcular score de regras para todos\n",
    "df['score_regras'] = df.apply(regras_alta_confianca, axis=1)\n",
    "\n",
    "# Predi√ß√£o final com h√≠brido\n",
    "df['PROBA_PAR_PRECISAO'] = y_proba_all\n",
    "df['PRED_ALTA_CONFIANCA'] = (\n",
    "    (df['PROBA_PAR_PRECISAO'] >= 0.7) & \n",
    "    (df['score_regras'] >= 7)\n",
    ").astype(int)\n",
    "\n",
    "df['RANK_PRECISAO'] = df['PROBA_PAR_PRECISAO'].rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar novos pares de alta confian√ßa\n",
    "novos_alta_confianca = df[\n",
    "    (df['PAR'] == 0) & \n",
    "    (df['PRED_ALTA_CONFIANCA'] == 1)\n",
    "].sort_values('PROBA_PAR_PRECISAO', ascending=False)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"NOVOS PARES DE ALTA CONFIAN√áA IDENTIFICADOS\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nTotal de candidatos: {len(novos_alta_confianca):,}\")\n",
    "\n",
    "if len(novos_alta_confianca) > 0:\n",
    "    print(f\"\\nDistribui√ß√£o por PASSO:\")\n",
    "    print(novos_alta_confianca['PASSO'].value_counts().sort_index())\n",
    "    \n",
    "    print(f\"\\nDistribui√ß√£o por C_SITUENCE:\")\n",
    "    situacao_map = {1: 'Cura', 2: 'Abandono', 3: '√ìbito TB', 4: '√ìbito outras', \n",
    "                    5: 'Transfer√™ncia', 6: 'Mudan√ßa diag', 7: 'TBDR'}\n",
    "    for sit, count in novos_alta_confianca['C_SITUENCE'].value_counts().head(7).items():\n",
    "        nome = situacao_map.get(int(sit), str(sit))\n",
    "        print(f\"  {nome}: {count}\")\n",
    "    \n",
    "    # Estat√≠sticas dos candidatos\n",
    "    print(f\"\\nEstat√≠sticas dos candidatos:\")\n",
    "    print(f\"  Nota final m√©dia: {novos_alta_confianca['nota final'].mean():.2f}\")\n",
    "    print(f\"  Score regras m√©dio: {novos_alta_confianca['score_regras'].mean():.2f}\")\n",
    "    print(f\"  Probabilidade ML m√©dia: {novos_alta_confianca['PROBA_PAR_PRECISAO'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamb√©m identificar candidatos com crit√©rio mais relaxado (para refer√™ncia)\n",
    "novos_media_confianca = df[\n",
    "    (df['PAR'] == 0) & \n",
    "    (df['PROBA_PAR_PRECISAO'] >= 0.6) &\n",
    "    (df['score_regras'] >= 5)\n",
    "].sort_values('PROBA_PAR_PRECISAO', ascending=False)\n",
    "\n",
    "print(f\"\\nCandidatos com crit√©rio m√©dio (ML>=0.6, Regras>=5): {len(novos_media_confianca):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar resultados\n",
    "cols_export = [\n",
    "    'PASSO', 'PROBA_PAR_PRECISAO', 'RANK_PRECISAO', 'score_regras',\n",
    "    'nota final', 'C_SITUENCE', 'R_DTNASC', 'C_DTNASC', \n",
    "    'R_BAIRES', 'C_BAIRES', 'R_IDLINHA', 'C_IDLINHA', 'C_IDPESSOA'\n",
    "]\n",
    "\n",
    "# Alta confian√ßa\n",
    "if len(novos_alta_confianca) > 0:\n",
    "    export_alta = novos_alta_confianca[[c for c in cols_export if c in df.columns]]\n",
    "    export_alta.to_csv('candidatos_precisao_alta_confianca.csv', index=False, sep=';', decimal=',')\n",
    "    print(f\"\\n‚úÖ Exportados {len(export_alta):,} candidatos de ALTA CONFIAN√áA\")\n",
    "    print(f\"   Arquivo: 'candidatos_precisao_alta_confianca.csv'\")\n",
    "\n",
    "# M√©dia confian√ßa\n",
    "if len(novos_media_confianca) > 0:\n",
    "    export_media = novos_media_confianca[[c for c in cols_export if c in df.columns]]\n",
    "    export_media.to_csv('candidatos_precisao_media_confianca.csv', index=False, sep=';', decimal=',')\n",
    "    print(f\"\\n‚úÖ Exportados {len(export_media):,} candidatos de M√âDIA CONFIAN√áA\")\n",
    "    print(f\"   Arquivo: 'candidatos_precisao_media_confianca.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. An√°lise de Confiabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisar caracter√≠sticas dos candidatos vs pares verdadeiros\n",
    "print(\"\\nCompara√ß√£o: Candidatos vs Pares Verdadeiros\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pares_verdadeiros = df[df['PAR'].isin([1, 2])]\n",
    "\n",
    "features_compare = ['nota final', 'NOME qtd frag iguais', 'DTNASC dt iguais', \n",
    "                    'NOMEMAE qtd frag iguais', 'score_regras']\n",
    "\n",
    "if len(novos_alta_confianca) > 0:\n",
    "    print(\"\\nCaracter√≠sticas:\")\n",
    "    for feat in features_compare:\n",
    "        if feat in df.columns:\n",
    "            mean_pares = pares_verdadeiros[feat].mean()\n",
    "            mean_novos = novos_alta_confianca[feat].mean()\n",
    "            diff_pct = ((mean_novos - mean_pares) / mean_pares * 100) if mean_pares != 0 else 0\n",
    "            print(f\"  {feat}:\")\n",
    "            print(f\"    Pares verdadeiros: {mean_pares:.3f}\")\n",
    "            print(f\"    Candidatos:        {mean_novos:.3f} ({diff_pct:+.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribui√ß√£o de probabilidades\n",
    "if len(novos_alta_confianca) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Plot 1: Distribui√ß√£o de probabilidade ML\n",
    "    ax1 = axes[0]\n",
    "    ax1.hist(pares_verdadeiros['PROBA_PAR_PRECISAO'], bins=30, alpha=0.7, \n",
    "             label='Pares Verdadeiros', color='green', density=True)\n",
    "    ax1.hist(novos_alta_confianca['PROBA_PAR_PRECISAO'], bins=30, alpha=0.7,\n",
    "             label='Novos Candidatos', color='blue', density=True)\n",
    "    ax1.axvline(x=0.7, color='red', linestyle='--', label='Threshold')\n",
    "    ax1.set_xlabel('Probabilidade ML', fontsize=12)\n",
    "    ax1.set_ylabel('Densidade', fontsize=12)\n",
    "    ax1.set_title('Distribui√ß√£o de Probabilidade ML', fontsize=14)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot 2: Distribui√ß√£o de score de regras\n",
    "    ax2 = axes[1]\n",
    "    ax2.hist(pares_verdadeiros['score_regras'], bins=20, alpha=0.7,\n",
    "             label='Pares Verdadeiros', color='green', density=True)\n",
    "    ax2.hist(novos_alta_confianca['score_regras'], bins=20, alpha=0.7,\n",
    "             label='Novos Candidatos', color='blue', density=True)\n",
    "    ax2.axvline(x=7, color='red', linestyle='--', label='Threshold')\n",
    "    ax2.set_xlabel('Score de Regras', fontsize=12)\n",
    "    ax2.set_ylabel('Densidade', fontsize=12)\n",
    "    ax2.set_title('Distribui√ß√£o de Score de Regras', fontsize=14)\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('distribuicao_candidatos_precisao.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Resumo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMO - ESTRAT√âGIA DE M√ÅXIMA PRECIS√ÉO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    "MODELO RECOMENDADO:\n",
    "  H√≠brido: Stacking ML + Regras de Neg√≥cio\n",
    "  \n",
    "CRIT√âRIOS DE CLASSIFICA√á√ÉO:\n",
    "  - Probabilidade ML >= 0.7\n",
    "  - Score de regras >= 7\n",
    "  - (Ambos devem ser satisfeitos)\n",
    "\n",
    "M√âTRICAS ESTIMADAS:\n",
    "  - Precision: ~{best_result['precision']*100:.0f}%+\n",
    "  - Recall: ~{best_result['recall']*100:.0f}%\n",
    "\n",
    "RESULTADOS:\n",
    "  - Candidatos alta confian√ßa: {len(novos_alta_confianca):,}\n",
    "  - Candidatos m√©dia confian√ßa: {len(novos_media_confianca):,}\n",
    "\n",
    "ARQUIVOS GERADOS:\n",
    "  1. candidatos_precisao_alta_confianca.csv\n",
    "  2. candidatos_precisao_media_confianca.csv\n",
    "\n",
    "VANTAGENS DESTA ABORDAGEM:\n",
    "  ‚úì Alta taxa de verdadeiros positivos\n",
    "  ‚úì Menor necessidade de revis√£o manual\n",
    "  ‚úì Pares identificados t√™m alta confiabilidade\n",
    "  ‚úì Regras interpret√°veis e audit√°veis\n",
    "\n",
    "LIMITA√á√ïES:\n",
    "  ‚úó Pode perder pares verdadeiros com dados incompletos\n",
    "  ‚úó Recall mais baixo que estrat√©gia agressiva\n",
    "\n",
    "RECOMENDA√á√ÉO:\n",
    "  Usar candidatos de ALTA CONFIAN√áA como pares confirmados.\n",
    "  Revisar candidatos de M√âDIA CONFIAN√áA manualmente.\n",
    "\"\"\")\n",
    "\n",
    "# Salvar modelos\n",
    "import joblib\n",
    "joblib.dump(stacking_precision, 'modelo_precisao.joblib')\n",
    "joblib.dump(scaler, 'scaler_precisao.joblib')\n",
    "print(\"\\n‚úÖ Modelos salvos em 'modelo_precisao.joblib'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
