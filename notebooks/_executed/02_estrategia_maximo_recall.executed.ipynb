{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea5ac1e8",
   "metadata": {
    "papermill": {
     "duration": 0.007495,
     "end_time": "2026-01-17T14:03:05.346140",
     "exception": false,
     "start_time": "2026-01-17T14:03:05.338645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üéØ Estrat√©gia de M√°ximo RECALL para Data Linkage\n",
    "## Objetivo: Encontrar o M√°ximo de Pares Verdadeiros\n",
    "\n",
    "Este notebook implementa uma estrat√©gia agressiva para **maximizar a sensibilidade** do linkage, aceitando um aumento de falsos positivos em troca de capturar mais pares verdadeiros.\n",
    "\n",
    "### T√©cnicas Implementadas:\n",
    "1. **Ensemble com Soft Voting** - Combina m√∫ltiplos modelos\n",
    "2. **SMOTE + Undersampling** - Balanceamento agressivo\n",
    "3. **Threshold Otimizado para Recall** - Ponto de corte baixo\n",
    "4. **Cost-Sensitive Learning** - Penaliza√ß√£o maior para falsos negativos\n",
    "5. **Cascade Classifier** - M√∫ltiplas etapas de classifica√ß√£o\n",
    "6. **Feature Engineering Extensivo** - Novas vari√°veis discriminativas\n",
    "7. **Neural Network com Class Weights** - Deep Learning com balanceamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eceb438",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:03:05.353651Z",
     "iopub.status.busy": "2026-01-17T14:03:05.352644Z",
     "iopub.status.idle": "2026-01-17T14:04:15.340279Z",
     "shell.execute_reply": "2026-01-17T14:04:15.340279Z"
    },
    "papermill": {
     "duration": 69.994144,
     "end_time": "2026-01-17T14:04:15.343283",
     "exception": false,
     "start_time": "2026-01-17T14:03:05.349139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mediapipe 0.10.14 requires protobuf<5,>=4.25.3, but you have protobuf 6.33.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# Instala√ß√£o de depend√™ncias\n",
    "!pip install -q pandas numpy scikit-learn xgboost lightgbm imbalanced-learn matplotlib seaborn tensorflow keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4c6b2db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:04:15.349790Z",
     "iopub.status.busy": "2026-01-17T14:04:15.349790Z",
     "iopub.status.idle": "2026-01-17T14:04:17.117817Z",
     "shell.execute_reply": "2026-01-17T14:04:17.117817Z"
    },
    "papermill": {
     "duration": 1.773032,
     "end_time": "2026-01-17T14:04:17.118823",
     "exception": false,
     "start_time": "2026-01-17T14:04:15.345791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bibliotecas carregadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier, \n",
    "    VotingClassifier, AdaBoostClassifier, BaggingClassifier\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    precision_recall_curve, f1_score, precision_score, recall_score,\n",
    "    average_precision_score, make_scorer\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√µes\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Bibliotecas carregadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4695fa9f",
   "metadata": {
    "papermill": {
     "duration": 0.003005,
     "end_time": "2026-01-17T14:04:17.125330",
     "exception": false,
     "start_time": "2026-01-17T14:04:17.122325",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Carregamento e Prepara√ß√£o Avan√ßada dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f127877",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:04:17.133844Z",
     "iopub.status.busy": "2026-01-17T14:04:17.132843Z",
     "iopub.status.idle": "2026-01-17T14:04:18.726662Z",
     "shell.execute_reply": "2026-01-17T14:04:18.726662Z"
    },
    "papermill": {
     "duration": 1.598337,
     "end_time": "2026-01-17T14:04:18.727667",
     "exception": false,
     "start_time": "2026-01-17T14:04:17.129330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo arquivo: D:\\git\\phd-research\\data\\COMPARADORSEMIDENT.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 61,696 registros\n",
      "Pares verdadeiros: 247 (0.40%)\n"
     ]
    }
   ],
   "source": [
    "# Carregar dados\n",
    "from pathlib import Path\n",
    "\n",
    "def find_data_path(filename: str = 'COMPARADORSEMIDENT.csv') -> Path:\n",
    "    for base in (Path.cwd(), *Path.cwd().parents):\n",
    "        candidate = base / 'data' / filename\n",
    "        if candidate.exists():\n",
    "            return candidate\n",
    "    raise FileNotFoundError(\n",
    "        f\"Nao foi possivel localizar data/{filename}. CWD={Path.cwd()}\"\n",
    "    )\n",
    "\n",
    "DATA_PATH = find_data_path()\n",
    "df = pd.read_csv(DATA_PATH, sep=';', low_memory=False)\n",
    "print(f\"Lendo arquivo: {DATA_PATH.resolve()}\")\n",
    "\n",
    "# Limpar nomes das colunas\n",
    "def clean_col(col):\n",
    "    return col.split(',')[0] if ',' in col else col\n",
    "df.columns = [clean_col(c) for c in df.columns]\n",
    "\n",
    "# Converter colunas num√©ricas\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == object:\n",
    "        try:\n",
    "            df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', '.'), errors='coerce')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# Target\n",
    "df['TARGET'] = (df['PAR'].isin([1, 2])).astype(int)\n",
    "\n",
    "print(f\"Dataset: {df.shape[0]:,} registros\")\n",
    "print(f\"Pares verdadeiros: {df['TARGET'].sum()} ({df['TARGET'].mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62bf2100",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:04:18.735178Z",
     "iopub.status.busy": "2026-01-17T14:04:18.735178Z",
     "iopub.status.idle": "2026-01-17T14:04:18.882173Z",
     "shell.execute_reply": "2026-01-17T14:04:18.882173Z"
    },
    "papermill": {
     "duration": 0.152513,
     "end_time": "2026-01-17T14:04:18.883178",
     "exception": false,
     "start_time": "2026-01-17T14:04:18.730665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features base: 29\n",
      "\n",
      "Total de features ap√≥s engineering: 58\n",
      "Novas features criadas: 29\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering Extensivo para Maximizar Recall\n",
    "\n",
    "# Features base\n",
    "SCORE_COLS = [\n",
    "    'NOME prim frag igual', 'NOME ult frag igual', 'NOME qtd frag iguais',\n",
    "    'NOME qtd frag raros', 'NOME qtd frag comuns', 'NOME qtd frag muito parec', 'NOME qtd frag abrev',\n",
    "    'NOMEMAE prim frag igual', 'NOMEMAE ult frag igual', 'NOMEMAE qtd frag iguais',\n",
    "    'NOMEMAE qtd frag raros', 'NOMEMAE qtd frag comuns', 'NOMEMAE qtd frag muito parec', 'NOMEMAE qtd frag abrev',\n",
    "    'DTNASC dt iguais', 'DTNASC dt ap 1digi', 'DTNASC dt inv dia', 'DTNASC dt inv mes', 'DTNASC dt inv ano',\n",
    "    'CODMUNRES uf igual', 'CODMUNRES local igual', 'CODMUNRES local prox',\n",
    "    'ENDERECO via igual', 'ENDERECO via prox', 'ENDERECO numero igual',\n",
    "    'ENDERECO compl prox', 'ENDERECO texto prox', 'ENDERECO tokens jacc',\n",
    "    'nota final'\n",
    "]\n",
    "\n",
    "available_cols = [c for c in SCORE_COLS if c in df.columns]\n",
    "X = df[available_cols].fillna(0).copy()\n",
    "\n",
    "print(f\"Features base: {len(available_cols)}\")\n",
    "\n",
    "# ============================================\n",
    "# FEATURE ENGINEERING AVAN√áADO\n",
    "# ============================================\n",
    "\n",
    "# 1. Scores agregados\n",
    "X['nome_total'] = X['NOME prim frag igual'] + X['NOME ult frag igual'] + X['NOME qtd frag iguais'] + X['NOME qtd frag muito parec']\n",
    "X['mae_total'] = X['NOMEMAE prim frag igual'] + X['NOMEMAE ult frag igual'] + X['NOMEMAE qtd frag iguais']\n",
    "X['dtnasc_total'] = X['DTNASC dt iguais'] + X['DTNASC dt ap 1digi'] * 0.8 + X['DTNASC dt inv dia'] * 0.5\n",
    "X['endereco_total'] = X['ENDERECO via igual'] + X['ENDERECO via prox'] * 0.7 + X['ENDERECO texto prox']\n",
    "X['local_total'] = X['CODMUNRES local igual'] + X['CODMUNRES local prox'] * 0.5\n",
    "\n",
    "# 2. Score ponderado customizado (otimizado para recall)\n",
    "X['score_recall'] = (\n",
    "    X['NOME qtd frag iguais'] * 3.0 +\n",
    "    X['NOME prim frag igual'] * 2.0 +\n",
    "    X['DTNASC dt iguais'] * 2.5 +\n",
    "    X['DTNASC dt ap 1digi'] * 2.0 +  # Aumentar peso para datas aproximadas\n",
    "    X['NOMEMAE qtd frag iguais'] * 1.5 +\n",
    "    X['CODMUNRES local igual'] * 1.0 +\n",
    "    X['ENDERECO via igual'] * 0.5\n",
    ")\n",
    "\n",
    "# 3. Intera√ß√µes multiplicativas\n",
    "X['nome_x_dtnasc'] = X['NOME qtd frag iguais'] * (X['DTNASC dt iguais'] + X['DTNASC dt ap 1digi'])\n",
    "X['nome_x_mae'] = X['NOME qtd frag iguais'] * X['NOMEMAE qtd frag iguais']\n",
    "X['nome_x_local'] = X['NOME qtd frag iguais'] * X['CODMUNRES local igual']\n",
    "X['dtnasc_x_local'] = X['dtnasc_total'] * X['local_total']\n",
    "X['nome_x_endereco'] = X['nome_total'] * X['endereco_total']\n",
    "\n",
    "# 4. Flags bin√°rios (relaxados para capturar mais casos)\n",
    "X['nome_bom'] = (X['NOME qtd frag iguais'] >= 0.7).astype(int)  # Relaxado de 0.95\n",
    "X['nome_prim_ok'] = (X['NOME prim frag igual'] >= 0.8).astype(int)\n",
    "X['dtnasc_ok'] = ((X['DTNASC dt iguais'] == 1) | (X['DTNASC dt ap 1digi'] == 1)).astype(int)  # Aceita aproximado\n",
    "X['dtnasc_parcial'] = ((X['DTNASC dt inv dia'] == 1) | (X['DTNASC dt inv mes'] == 1)).astype(int)\n",
    "X['mae_presente'] = (X['NOMEMAE qtd frag iguais'] > 0.3).astype(int)  # Relaxado\n",
    "X['local_ok'] = (X['CODMUNRES local igual'] >= 0.8).astype(int)\n",
    "\n",
    "# 5. Contagem de evid√™ncias positivas\n",
    "X['evidencias_positivas'] = (\n",
    "    X['nome_bom'] + X['nome_prim_ok'] + X['dtnasc_ok'] + \n",
    "    X['dtnasc_parcial'] + X['mae_presente'] + X['local_ok']\n",
    ")\n",
    "\n",
    "# 6. Score de confian√ßa m√≠nima (para catch-all)\n",
    "X['min_score_nome'] = X[['NOME prim frag igual', 'NOME ult frag igual', 'NOME qtd frag iguais']].min(axis=1)\n",
    "X['max_score_dtnasc'] = X[['DTNASC dt iguais', 'DTNASC dt ap 1digi']].max(axis=1)\n",
    "\n",
    "# 7. Raz√µes e propor√ß√µes\n",
    "X['ratio_nome_mae'] = X['nome_total'] / (X['mae_total'] + 0.1)\n",
    "X['ratio_nome_nota'] = X['nome_total'] / (X['nota final'] + 0.1)\n",
    "\n",
    "# 8. Vari√°veis do contexto (situa√ß√£o de encerramento)\n",
    "X['obito_sinan'] = df['C_SITUENCE'].isin([3, 4]).astype(int)\n",
    "X['obito_tb'] = (df['C_SITUENCE'] == 3).astype(int)\n",
    "\n",
    "# 9. Diferen√ßa de datas (proxy para verificar consist√™ncia temporal)\n",
    "df['R_DT_ANO'] = df['R_DTNASC'].astype(str).str[:4].astype(float)\n",
    "df['C_DT_ANO'] = df['C_DTNASC'].astype(str).str[:4].astype(float)\n",
    "X['diff_ano_nasc'] = np.abs(df['R_DT_ANO'] - df['C_DT_ANO']).fillna(99)\n",
    "X['diff_ano_ok'] = (X['diff_ano_nasc'] <= 5).astype(int)  # Aceita at√© 5 anos de diferen√ßa\n",
    "\n",
    "# 10. Polin√¥mios de features importantes\n",
    "X['nome_squared'] = X['NOME qtd frag iguais'] ** 2\n",
    "X['dtnasc_squared'] = X['DTNASC dt iguais'] ** 2\n",
    "X['nota_squared'] = X['nota final'] ** 2\n",
    "\n",
    "print(f\"\\nTotal de features ap√≥s engineering: {X.shape[1]}\")\n",
    "print(f\"Novas features criadas: {X.shape[1] - len(available_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3f1f28b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:04:18.891691Z",
     "iopub.status.busy": "2026-01-17T14:04:18.891691Z",
     "iopub.status.idle": "2026-01-17T14:04:18.987944Z",
     "shell.execute_reply": "2026-01-17T14:04:18.987276Z"
    },
    "papermill": {
     "duration": 0.102106,
     "end_time": "2026-01-17T14:04:18.988789",
     "exception": false,
     "start_time": "2026-01-17T14:04:18.886683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino: 43,187 (173 pares)\n",
      "Teste: 18,509 (74 pares)\n"
     ]
    }
   ],
   "source": [
    "# Preparar dados\n",
    "y = df['TARGET'].copy()\n",
    "\n",
    "# Divis√£o estratificada\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Guardar √≠ndices originais\n",
    "train_idx = X_train.index\n",
    "test_idx = X_test.index\n",
    "\n",
    "print(f\"Treino: {len(X_train):,} ({y_train.sum()} pares)\")\n",
    "print(f\"Teste: {len(X_test):,} ({y_test.sum()} pares)\")\n",
    "\n",
    "# Normaliza√ß√£o\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0a97dc",
   "metadata": {
    "papermill": {
     "duration": 0.003597,
     "end_time": "2026-01-17T14:04:18.996386",
     "exception": false,
     "start_time": "2026-01-17T14:04:18.992789",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Balanceamento Agressivo com SMOTE + Variantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b8594a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:04:19.003300Z",
     "iopub.status.busy": "2026-01-17T14:04:19.003300Z",
     "iopub.status.idle": "2026-01-17T14:04:28.353081Z",
     "shell.execute_reply": "2026-01-17T14:04:28.353081Z"
    },
    "papermill": {
     "duration": 9.354789,
     "end_time": "2026-01-17T14:04:28.354088",
     "exception": false,
     "start_time": "2026-01-17T14:04:18.999299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando t√©cnicas de balanceamento...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE: 86,028 amostras (pares: 43,014)\n",
      "BorderlineSMOTE: 86,028 amostras (pares: 43,014)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN: 86,027 amostras (pares: 43,013)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTETomek: 86,026 amostras (pares: 43,013)\n",
      "SMOTE Extremo (1:1): 86,028 amostras (pares: 43,014)\n"
     ]
    }
   ],
   "source": [
    "# Testar diferentes estrat√©gias de balanceamento\n",
    "print(\"Aplicando t√©cnicas de balanceamento...\\n\")\n",
    "\n",
    "# 1. SMOTE padr√£o\n",
    "smote = SMOTE(random_state=42, k_neighbors=3)\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
    "print(f\"SMOTE: {len(y_smote):,} amostras (pares: {y_smote.sum():,})\")\n",
    "\n",
    "# 2. BorderlineSMOTE (foca nos casos de fronteira)\n",
    "bsmote = BorderlineSMOTE(random_state=42, k_neighbors=3)\n",
    "X_bsmote, y_bsmote = bsmote.fit_resample(X_train, y_train)\n",
    "print(f\"BorderlineSMOTE: {len(y_bsmote):,} amostras (pares: {y_bsmote.sum():,})\")\n",
    "\n",
    "# 3. ADASYN (adaptativo)\n",
    "adasyn = ADASYN(random_state=42, n_neighbors=3)\n",
    "X_adasyn, y_adasyn = adasyn.fit_resample(X_train, y_train)\n",
    "print(f\"ADASYN: {len(y_adasyn):,} amostras (pares: {y_adasyn.sum():,})\")\n",
    "\n",
    "# 4. SMOTE + Tomek Links (remove ru√≠do)\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_smtomek, y_smtomek = smote_tomek.fit_resample(X_train, y_train)\n",
    "print(f\"SMOTETomek: {len(y_smtomek):,} amostras (pares: {y_smtomek.sum():,})\")\n",
    "\n",
    "# 5. Oversampling extremo (ratio 1:1)\n",
    "smote_extreme = SMOTE(sampling_strategy=1.0, random_state=42, k_neighbors=3)\n",
    "X_extreme, y_extreme = smote_extreme.fit_resample(X_train, y_train)\n",
    "print(f\"SMOTE Extremo (1:1): {len(y_extreme):,} amostras (pares: {y_extreme.sum():,})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c57b58d",
   "metadata": {
    "papermill": {
     "duration": 0.002998,
     "end_time": "2026-01-17T14:04:28.360603",
     "exception": false,
     "start_time": "2026-01-17T14:04:28.357605",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Modelos Otimizados para Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec7bde3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:04:28.369172Z",
     "iopub.status.busy": "2026-01-17T14:04:28.368118Z",
     "iopub.status.idle": "2026-01-17T14:04:28.372053Z",
     "shell.execute_reply": "2026-01-17T14:04:28.372053Z"
    },
    "papermill": {
     "duration": 0.008957,
     "end_time": "2026-01-17T14:04:28.373562",
     "exception": false,
     "start_time": "2026-01-17T14:04:28.364605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fun√ß√£o para calcular m√©tricas\n",
    "def evaluate_model(model, X_tr, y_tr, X_te, y_te, model_name, threshold=0.5):\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_proba = model.predict_proba(X_te)[:, 1]\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    \n",
    "    return {\n",
    "        'name': model_name,\n",
    "        'precision': precision_score(y_te, y_pred),\n",
    "        'recall': recall_score(y_te, y_pred),\n",
    "        'f1': f1_score(y_te, y_pred),\n",
    "        'auc_roc': roc_auc_score(y_te, y_proba),\n",
    "        'auc_pr': average_precision_score(y_te, y_proba),\n",
    "        'y_proba': y_proba,\n",
    "        'model': model\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af44998e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2026-01-17T14:04:28.376566",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definir modelos com configura√ß√µes otimizadas para recall\n",
    "results = []\n",
    "\n",
    "# 1. Random Forest com class_weight extremo\n",
    "print(\"Treinando modelos...\\n\")\n",
    "\n",
    "rf_recall = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=15,\n",
    "    min_samples_leaf=1,\n",
    "    class_weight={0: 1, 1: 500},  # Peso extremo para classe minorit√°ria\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "res = evaluate_model(rf_recall, X_train.values, y_train, X_test.values, y_test, \n",
    "                     'RF Class Weight Extremo', threshold=0.3)\n",
    "results.append(res)\n",
    "print(f\"{res['name']}: Recall={res['recall']:.4f}, Precision={res['precision']:.4f}\")\n",
    "\n",
    "# 2. Random Forest + SMOTE\n",
    "rf_smote = RandomForestClassifier(\n",
    "    n_estimators=300, max_depth=12, random_state=42, n_jobs=-1\n",
    ")\n",
    "res = evaluate_model(rf_smote, X_smote.values, y_smote, X_test.values, y_test,\n",
    "                     'RF + SMOTE', threshold=0.3)\n",
    "results.append(res)\n",
    "print(f\"{res['name']}: Recall={res['recall']:.4f}, Precision={res['precision']:.4f}\")\n",
    "\n",
    "# 3. Random Forest + BorderlineSMOTE\n",
    "rf_bsmote = RandomForestClassifier(\n",
    "    n_estimators=300, max_depth=12, random_state=42, n_jobs=-1\n",
    ")\n",
    "res = evaluate_model(rf_bsmote, X_bsmote.values, y_bsmote, X_test.values, y_test,\n",
    "                     'RF + BorderlineSMOTE', threshold=0.3)\n",
    "results.append(res)\n",
    "print(f\"{res['name']}: Recall={res['recall']:.4f}, Precision={res['precision']:.4f}\")\n",
    "\n",
    "# 4. Gradient Boosting com sample_weight\n",
    "gb_recall = GradientBoostingClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "# Criar sample weights\n",
    "sample_weights = np.where(y_smote == 1, 10, 1)\n",
    "gb_recall.fit(X_smote.values, y_smote, sample_weight=sample_weights)\n",
    "y_proba_gb = gb_recall.predict_proba(X_test.values)[:, 1]\n",
    "y_pred_gb = (y_proba_gb >= 0.3).astype(int)\n",
    "res = {\n",
    "    'name': 'GB + SMOTE + Sample Weights',\n",
    "    'precision': precision_score(y_test, y_pred_gb),\n",
    "    'recall': recall_score(y_test, y_pred_gb),\n",
    "    'f1': f1_score(y_test, y_pred_gb),\n",
    "    'auc_roc': roc_auc_score(y_test, y_proba_gb),\n",
    "    'auc_pr': average_precision_score(y_test, y_proba_gb),\n",
    "    'y_proba': y_proba_gb,\n",
    "    'model': gb_recall\n",
    "}\n",
    "results.append(res)\n",
    "print(f\"{res['name']}: Recall={res['recall']:.4f}, Precision={res['precision']:.4f}\")\n",
    "\n",
    "# 5. AdaBoost (bom para recall)\n",
    "ada_recall = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=3),\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "res = evaluate_model(ada_recall, X_smote.values, y_smote, X_test.values, y_test,\n",
    "                     'AdaBoost + SMOTE', threshold=0.3)\n",
    "results.append(res)\n",
    "print(f\"{res['name']}: Recall={res['recall']:.4f}, Precision={res['precision']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf9210d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 6. Neural Network com class_weight\n",
    "print(\"\\nTreinando Neural Network...\")\n",
    "\n",
    "mlp_recall = MLPClassifier(\n",
    "    hidden_layer_sizes=(256, 128, 64, 32),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=500,\n",
    "    random_state=42,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1\n",
    ")\n",
    "\n",
    "# Usar SMOTE extremo para NN\n",
    "X_train_nn = scaler.fit_transform(X_extreme)\n",
    "X_test_nn = scaler.transform(X_test)\n",
    "\n",
    "mlp_recall.fit(X_train_nn, y_extreme)\n",
    "y_proba_nn = mlp_recall.predict_proba(X_test_nn)[:, 1]\n",
    "y_pred_nn = (y_proba_nn >= 0.25).astype(int)  # Threshold baixo\n",
    "\n",
    "res = {\n",
    "    'name': 'MLP + SMOTE Extremo (th=0.25)',\n",
    "    'precision': precision_score(y_test, y_pred_nn),\n",
    "    'recall': recall_score(y_test, y_pred_nn),\n",
    "    'f1': f1_score(y_test, y_pred_nn),\n",
    "    'auc_roc': roc_auc_score(y_test, y_proba_nn),\n",
    "    'auc_pr': average_precision_score(y_test, y_proba_nn),\n",
    "    'y_proba': y_proba_nn,\n",
    "    'model': mlp_recall\n",
    "}\n",
    "results.append(res)\n",
    "print(f\"{res['name']}: Recall={res['recall']:.4f}, Precision={res['precision']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fde3da5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4. Ensemble com Soft Voting (Maximizar Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eca4c60",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Criar ensemble de todos os modelos treinados\n",
    "print(\"Construindo Ensemble para M√°ximo Recall...\\n\")\n",
    "\n",
    "# Ensemble 1: Voting com modelos diversos\n",
    "ensemble_recall = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestClassifier(n_estimators=200, max_depth=12, \n",
    "                                      class_weight={0:1, 1:300}, random_state=42)),\n",
    "        ('gb', GradientBoostingClassifier(n_estimators=150, max_depth=5, random_state=42)),\n",
    "        ('ada', AdaBoostClassifier(n_estimators=150, random_state=42)),\n",
    "        ('knn', KNeighborsClassifier(n_neighbors=5, weights='distance'))\n",
    "    ],\n",
    "    voting='soft',\n",
    "    weights=[2, 1, 1, 1]  # Mais peso para RF\n",
    ")\n",
    "\n",
    "ensemble_recall.fit(X_smote.values, y_smote)\n",
    "y_proba_ens = ensemble_recall.predict_proba(X_test.values)[:, 1]\n",
    "\n",
    "# Testar diferentes thresholds\n",
    "print(\"Performance do Ensemble com diferentes thresholds:\")\n",
    "for th in [0.15, 0.20, 0.25, 0.30, 0.35, 0.40]:\n",
    "    y_pred_ens = (y_proba_ens >= th).astype(int)\n",
    "    rec = recall_score(y_test, y_pred_ens)\n",
    "    prec = precision_score(y_test, y_pred_ens)\n",
    "    f1 = f1_score(y_test, y_pred_ens)\n",
    "    print(f\"  Threshold {th}: Recall={rec:.4f}, Precision={prec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Usar threshold que maximize recall com precision > 1%\n",
    "best_th_recall = 0.15\n",
    "y_pred_ens_final = (y_proba_ens >= best_th_recall).astype(int)\n",
    "\n",
    "res = {\n",
    "    'name': f'Ensemble Soft Voting (th={best_th_recall})',\n",
    "    'precision': precision_score(y_test, y_pred_ens_final),\n",
    "    'recall': recall_score(y_test, y_pred_ens_final),\n",
    "    'f1': f1_score(y_test, y_pred_ens_final),\n",
    "    'auc_roc': roc_auc_score(y_test, y_proba_ens),\n",
    "    'auc_pr': average_precision_score(y_test, y_proba_ens),\n",
    "    'y_proba': y_proba_ens,\n",
    "    'model': ensemble_recall\n",
    "}\n",
    "results.append(res)\n",
    "print(f\"\\n>>> {res['name']}: Recall={res['recall']:.4f}, Precision={res['precision']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c174ea5f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 5. Cascade Classifier (M√∫ltiplos Est√°gios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c25eed",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cascade: Primeiro est√°gio filtra, segundo est√°gio refina\n",
    "print(\"Construindo Cascade Classifier...\\n\")\n",
    "\n",
    "# Est√°gio 1: Modelo com recall muito alto (aceita muitos falsos positivos)\n",
    "stage1 = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    class_weight={0: 1, 1: 1000},\n",
    "    random_state=42\n",
    ")\n",
    "stage1.fit(X_smote.values, y_smote)\n",
    "y_proba_s1 = stage1.predict_proba(X_test.values)[:, 1]\n",
    "y_pred_s1 = (y_proba_s1 >= 0.1).astype(int)  # Threshold muito baixo\n",
    "\n",
    "print(f\"Est√°gio 1: Recall={recall_score(y_test, y_pred_s1):.4f}, \" +\n",
    "      f\"Candidatos passados: {y_pred_s1.sum()}\")\n",
    "\n",
    "# Est√°gio 2: Refinar apenas os candidatos do est√°gio 1\n",
    "mask_s1 = y_pred_s1 == 1\n",
    "if mask_s1.sum() > 0:\n",
    "    X_stage2 = X_test.values[mask_s1]\n",
    "    y_stage2_true = y_test.values[mask_s1]\n",
    "    \n",
    "    stage2 = GradientBoostingClassifier(\n",
    "        n_estimators=150, max_depth=5, random_state=42\n",
    "    )\n",
    "    stage2.fit(X_smote.values, y_smote)\n",
    "    y_proba_s2 = stage2.predict_proba(X_stage2)[:, 1]\n",
    "    y_pred_s2 = (y_proba_s2 >= 0.2).astype(int)\n",
    "    \n",
    "    # Combinar predi√ß√µes\n",
    "    y_pred_cascade = np.zeros(len(y_test))\n",
    "    y_pred_cascade[mask_s1] = y_pred_s2\n",
    "    \n",
    "    y_proba_cascade = np.zeros(len(y_test))\n",
    "    y_proba_cascade[mask_s1] = y_proba_s2\n",
    "    \n",
    "    res = {\n",
    "        'name': 'Cascade (2 est√°gios)',\n",
    "        'precision': precision_score(y_test, y_pred_cascade),\n",
    "        'recall': recall_score(y_test, y_pred_cascade),\n",
    "        'f1': f1_score(y_test, y_pred_cascade),\n",
    "        'auc_roc': roc_auc_score(y_test, y_proba_cascade) if y_proba_cascade.max() > 0 else 0,\n",
    "        'auc_pr': average_precision_score(y_test, y_proba_cascade) if y_proba_cascade.max() > 0 else 0,\n",
    "        'y_proba': y_proba_cascade,\n",
    "        'model': (stage1, stage2)\n",
    "    }\n",
    "    results.append(res)\n",
    "    print(f\"\\n>>> {res['name']}: Recall={res['recall']:.4f}, Precision={res['precision']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7535d6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 6. Compara√ß√£o e Sele√ß√£o do Melhor Modelo para Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfdf6e0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Criar DataFrame de resultados\n",
    "df_results = pd.DataFrame([{\n",
    "    'Modelo': r['name'],\n",
    "    'Recall': r['recall'],\n",
    "    'Precision': r['precision'],\n",
    "    'F1': r['f1'],\n",
    "    'AUC-ROC': r['auc_roc'],\n",
    "    'AUC-PR': r['auc_pr']\n",
    "} for r in results])\n",
    "\n",
    "df_results = df_results.sort_values('Recall', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"RANKING DE MODELOS POR RECALL\")\n",
    "print(\"=\"*90)\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "# Identificar melhor modelo\n",
    "best_recall_idx = df_results['Recall'].idxmax()\n",
    "best_model_name = df_results.loc[best_recall_idx, 'Modelo']\n",
    "best_result = [r for r in results if r['name'] == best_model_name][0]\n",
    "\n",
    "print(f\"\\nüèÜ MELHOR MODELO PARA RECALL: {best_model_name}\")\n",
    "print(f\"   Recall: {best_result['recall']:.4f}\")\n",
    "print(f\"   Precision: {best_result['precision']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c86b774",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualiza√ß√£o\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Recall vs Precision\n",
    "ax1 = axes[0]\n",
    "colors = plt.cm.viridis(np.linspace(0, 0.8, len(df_results)))\n",
    "for idx, (_, row) in enumerate(df_results.iterrows()):\n",
    "    ax1.scatter(row['Precision'], row['Recall'], s=200, c=[colors[idx]], \n",
    "                label=row['Modelo'][:25], edgecolors='black', linewidth=1)\n",
    "ax1.set_xlabel('Precision', fontsize=12)\n",
    "ax1.set_ylabel('Recall', fontsize=12)\n",
    "ax1.set_title('Trade-off Precision vs Recall', fontsize=14)\n",
    "ax1.legend(loc='lower left', fontsize=8)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xlim(-0.05, 1.05)\n",
    "ax1.set_ylim(-0.05, 1.05)\n",
    "\n",
    "# Plot 2: Barras de Recall\n",
    "ax2 = axes[1]\n",
    "y_pos = np.arange(len(df_results))\n",
    "bars = ax2.barh(y_pos, df_results['Recall'], color='steelblue', edgecolor='black')\n",
    "ax2.set_yticks(y_pos)\n",
    "ax2.set_yticklabels([m[:30] for m in df_results['Modelo']])\n",
    "ax2.set_xlabel('Recall', fontsize=12)\n",
    "ax2.set_title('Compara√ß√£o de Recall por Modelo', fontsize=14)\n",
    "ax2.axvline(x=0.9, color='red', linestyle='--', label='Meta 90%')\n",
    "ax2.legend()\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for bar, val in zip(bars, df_results['Recall']):\n",
    "    ax2.text(val + 0.01, bar.get_y() + bar.get_height()/2, f'{val:.3f}', \n",
    "             va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('recall_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5cb40e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 7. Aplica√ß√£o aos Dados Completos e Identifica√ß√£o de Novos Pares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccbfe16",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Usar o melhor modelo (ensemble) para predizer em todos os dados\n",
    "print(\"Aplicando modelo a todos os dados...\\n\")\n",
    "\n",
    "# Treinar modelo final em todos os dados de treino\n",
    "final_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestClassifier(n_estimators=300, max_depth=15, \n",
    "                                      class_weight={0:1, 1:500}, random_state=42)),\n",
    "        ('gb', GradientBoostingClassifier(n_estimators=200, max_depth=6, random_state=42)),\n",
    "        ('ada', AdaBoostClassifier(n_estimators=200, random_state=42))\n",
    "    ],\n",
    "    voting='soft',\n",
    "    weights=[3, 1, 1]\n",
    ")\n",
    "\n",
    "# Aplicar SMOTE em todo o treino\n",
    "smote_final = SMOTE(sampling_strategy=0.5, random_state=42, k_neighbors=3)\n",
    "X_all_smote, y_all_smote = smote_final.fit_resample(X, y)\n",
    "\n",
    "final_model.fit(X_all_smote.values, y_all_smote)\n",
    "\n",
    "# Predi√ß√µes para todos os dados originais\n",
    "y_proba_final = final_model.predict_proba(X.values)[:, 1]\n",
    "df['PROBA_PAR_RECALL'] = y_proba_final\n",
    "df['RANK_RECALL'] = df['PROBA_PAR_RECALL'].rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb2be21",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identificar potenciais novos pares (n√£o-pares com alta probabilidade)\n",
    "threshold_recall = 0.20  # Threshold para maximizar recall\n",
    "\n",
    "novos_pares_potenciais = df[\n",
    "    (df['PAR'] == 0) & \n",
    "    (df['PROBA_PAR_RECALL'] >= threshold_recall)\n",
    "].sort_values('PROBA_PAR_RECALL', ascending=False)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"NOVOS PARES POTENCIAIS IDENTIFICADOS (threshold={threshold_recall})\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nTotal de candidatos: {len(novos_pares_potenciais):,}\")\n",
    "\n",
    "print(f\"\\nDistribui√ß√£o por PASSO:\")\n",
    "print(novos_pares_potenciais['PASSO'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nDistribui√ß√£o por C_SITUENCE:\")\n",
    "situacao_map = {1: 'Cura', 2: 'Abandono', 3: '√ìbito TB', 4: '√ìbito outras', \n",
    "                5: 'Transfer√™ncia', 6: 'Mudan√ßa diag', 7: 'TBDR'}\n",
    "for sit, count in novos_pares_potenciais['C_SITUENCE'].value_counts().head(7).items():\n",
    "    nome = situacao_map.get(int(sit), str(sit))\n",
    "    print(f\"  {nome}: {count} ({count/len(novos_pares_potenciais)*100:.1f}%)\")\n",
    "\n",
    "# Priorizar candidatos com √≥bito\n",
    "candidatos_obito = novos_pares_potenciais[novos_pares_potenciais['C_SITUENCE'].isin([3, 4])]\n",
    "print(f\"\\n>>> Candidatos com √ìBITO no SINAN: {len(candidatos_obito)} ({len(candidatos_obito)/len(novos_pares_potenciais)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45de3503",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# An√°lise das caracter√≠sticas dos novos candidatos\n",
    "print(\"\\nCaracter√≠sticas dos novos candidatos vs pares verdadeiros:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "pares_verdadeiros = df[df['PAR'].isin([1, 2])]\n",
    "\n",
    "features_compare = ['nota final', 'NOME qtd frag iguais', 'DTNASC dt iguais', \n",
    "                    'DTNASC dt ap 1digi', 'NOMEMAE qtd frag iguais']\n",
    "\n",
    "for feat in features_compare:\n",
    "    if feat in df.columns:\n",
    "        mean_pares = pares_verdadeiros[feat].mean()\n",
    "        mean_novos = novos_pares_potenciais[feat].mean()\n",
    "        print(f\"{feat}:\")\n",
    "        print(f\"  Pares verdadeiros: {mean_pares:.3f}\")\n",
    "        print(f\"  Novos candidatos:  {mean_novos:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09d9db1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Exportar candidatos para revis√£o\n",
    "cols_export = [\n",
    "    'PASSO', 'PROBA_PAR_RECALL', 'RANK_RECALL', 'nota final',\n",
    "    'C_SITUENCE', 'R_DTNASC', 'C_DTNASC', 'R_BAIRES', 'C_BAIRES',\n",
    "    'R_IDLINHA', 'C_IDLINHA', 'C_IDPESSOA'\n",
    "]\n",
    "\n",
    "# Exportar todos os candidatos\n",
    "export_df = novos_pares_potenciais[[c for c in cols_export if c in df.columns]].copy()\n",
    "export_df = export_df.sort_values('PROBA_PAR_RECALL', ascending=False)\n",
    "\n",
    "# Salvar arquivos\n",
    "export_df.to_csv('candidatos_recall_todos.csv', index=False, sep=';', decimal=',')\n",
    "print(f\"\\n‚úÖ Exportados {len(export_df):,} candidatos para 'candidatos_recall_todos.csv'\")\n",
    "\n",
    "# Exportar apenas os com √≥bito (prioridade)\n",
    "export_obito = export_df[export_df['C_SITUENCE'].isin([3, 4])]\n",
    "export_obito.to_csv('candidatos_recall_obito_prioritario.csv', index=False, sep=';', decimal=',')\n",
    "print(f\"‚úÖ Exportados {len(export_obito):,} candidatos priorit√°rios (√≥bito) para 'candidatos_recall_obito_prioritario.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff492c6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 8. Estimativa de Impacto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31e4fd4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Estimar quantos novos pares seriam encontrados\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ESTIMATIVA DE IMPACTO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Baseado na taxa de verdadeiros positivos no conjunto de teste\n",
    "recall_obtido = best_result['recall']\n",
    "precision_obtida = best_result['precision']\n",
    "\n",
    "pares_atuais = df['TARGET'].sum()\n",
    "candidatos_novos = len(novos_pares_potenciais)\n",
    "novos_pares_estimados = int(candidatos_novos * precision_obtida)\n",
    "\n",
    "print(f\"\"\"\n",
    "Situa√ß√£o atual:\n",
    "  - Pares identificados: {pares_atuais}\n",
    "\n",
    "Com o modelo de m√°ximo recall:\n",
    "  - Recall estimado: {recall_obtido:.1%}\n",
    "  - Precision estimada: {precision_obtida:.1%}\n",
    "  - Candidatos para revis√£o: {candidatos_novos:,}\n",
    "  - Novos pares estimados: ~{novos_pares_estimados}\n",
    "\n",
    "Candidatos priorit√°rios (√≥bito SINAN):\n",
    "  - Total: {len(candidatos_obito):,}\n",
    "  - Novos pares estimados neste grupo: ~{int(len(candidatos_obito) * precision_obtida * 1.5)}\n",
    "    (taxa maior esperada por ter √≥bito registrado)\n",
    "\n",
    ">>> AUMENTO POTENCIAL: +{novos_pares_estimados/pares_atuais*100:.0f}% de pares\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea002f0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Resumo final\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMO - ESTRAT√âGIA DE M√ÅXIMO RECALL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    "MODELO RECOMENDADO:\n",
    "  {best_model_name}\n",
    "\n",
    "M√âTRICAS NO TESTE:\n",
    "  - Recall: {best_result['recall']:.4f} ({best_result['recall']*100:.1f}%)\n",
    "  - Precision: {best_result['precision']:.4f} ({best_result['precision']*100:.1f}%)\n",
    "  - AUC-PR: {best_result['auc_pr']:.4f}\n",
    "\n",
    "ARQUIVOS GERADOS:\n",
    "  1. candidatos_recall_todos.csv - Todos os candidatos ({len(export_df):,})\n",
    "  2. candidatos_recall_obito_prioritario.csv - Priorit√°rios ({len(export_obito):,})\n",
    "\n",
    "PR√ìXIMOS PASSOS:\n",
    "  1. Revisar candidatos_recall_obito_prioritario.csv primeiro\n",
    "  2. Validar pares encontrados com documentos fonte\n",
    "  3. Ajustar threshold se necess√°rio baseado na revis√£o\n",
    "\"\"\")\n",
    "\n",
    "# Salvar modelo\n",
    "import joblib\n",
    "joblib.dump(final_model, 'modelo_recall.joblib')\n",
    "joblib.dump(scaler, 'scaler_recall.joblib')\n",
    "print(\"\\n‚úÖ Modelo salvo em 'modelo_recall.joblib'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "notebooks/02_estrategia_maximo_recall.ipynb",
   "output_path": "notebooks/_executed/02_estrategia_maximo_recall.executed.ipynb",
   "parameters": {},
   "start_time": "2026-01-17T14:03:03.599221",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}